#!/usr/bin/env python3
"""
ChunkBuffer ì„±ëŠ¥ í…ŒìŠ¤íŠ¸ ìŠ¤í¬ë¦½íŠ¸
- ìƒˆë¡œìš´ ì—„ê²©í•œ ì„¤ì • í…ŒìŠ¤íŠ¸
- ì‘ì€ ì²­í¬ ë°©ì§€ íš¨ê³¼ í™•ì¸
- ì„±ëŠ¥ í†µê³„ ë¶„ì„
"""

import sys
import time
import json
from typing import List, Dict, Any

# ChunkBuffer í´ë˜ìŠ¤ë¥¼ ì„í¬íŠ¸í•˜ê¸° ìœ„í•´ ê²½ë¡œ ì¶”ê°€
sys.path.append('./app')

# ëª¨ì˜ ì„¤ì • í´ë˜ìŠ¤
class MockSettings:
    @staticmethod
    def should_log_performance():
        return True
    
    @staticmethod 
    def should_log_debug():
        return True

# ì „ì—­ settings ê°ì²´ ìƒì„± (ChunkBufferì—ì„œ ì‚¬ìš©)
import app.core.config as config
config.settings = MockSettings()

from app.services.vllm_integration_service import ChunkBuffer

def simulate_ai_tokens() -> List[str]:
    """AI ëª¨ë¸ì´ ìƒì„±í•˜ëŠ” ë‹¤ì–‘í•œ í¬ê¸°ì˜ í† í°ë“¤ì„ ì‹œë®¬ë ˆì´ì…˜"""
    return [
        # ë§¤ìš° ì‘ì€ í† í°ë“¤ (ê¸°ì¡´ ë¬¸ì œ)
        "def", " ", "hello", "(", ")", ":", "\n",
        "    ", "print", "(", "\"", "Hello", ",", " ", "world", "!", "\"", ")", "\n",
        
        # ì¤‘ê°„ í¬ê¸° í† í°ë“¤
        "def calculate_sum", "(", "numbers", ":", " ", "list", ")", ":", "\n",
        "    ", "total", " ", "=", " ", "0", "\n",
        "    ", "for", " ", "num", " ", "in", " ", "numbers", ":", "\n",
        "        ", "total", " ", "+=", " ", "num", "\n",
        "    ", "return", " ", "total", "\n\n",
        
        # ì½”ë“œ ë¸”ë¡
        "class DataProcessor:\n",
        "    def __init__(self, data):\n",
        "        self.data = data\n",
        "        self.processed = False\n\n",
        "    def process(self):\n",
        "        if not self.processed:\n",
        "            self.data = [x * 2 for x in self.data]\n",
        "            self.processed = True\n",
        "        return self.data\n\n",
        
        # ì£¼ì„ê³¼ ë¬¸ì„œí™”
        "# ì´ í•¨ìˆ˜ëŠ” ì‚¬ìš©ì ì…ë ¥ì„ ê²€ì¦í•©ë‹ˆë‹¤\n",
        '"""Multi-line docstring explaining\n',
        'the purpose of this function and its\n',
        'parameters and return values."""\n\n',
        
        # ì¢…ë£Œ í† í°
        "<|im_end|>"
    ]

def test_chunk_buffer_performance():
    """ChunkBuffer ì„±ëŠ¥ í…ŒìŠ¤íŠ¸"""
    print("ğŸ§ª ChunkBuffer ì„±ëŠ¥ í…ŒìŠ¤íŠ¸ ì‹œì‘")
    print("=" * 60)
    
    # ê¸°ì¡´ ì„¤ì • í…ŒìŠ¤íŠ¸
    print("\n1ï¸âƒ£ ê¸°ì¡´ ì„¤ì • í…ŒìŠ¤íŠ¸ (ì™„í™” ëª¨ë“œ)")
    old_buffer = ChunkBuffer(buffer_size=200, buffer_timeout=0.5)
    old_buffer.strict_size_enforcement = False
    
    tokens = simulate_ai_tokens()
    old_chunks = []
    old_start = time.time()
    
    for token in tokens:
        result = old_buffer.add_chunk(token)
        if result:
            old_chunks.append(result)
    
    # ë§ˆì§€ë§‰ í”ŒëŸ¬ì‹œ
    final_old = old_buffer.force_flush()
    if final_old:
        old_chunks.append(final_old)
    
    old_duration = time.time() - old_start
    old_stats = old_buffer.get_performance_stats()
    
    print(f"ğŸ“Š ê¸°ì¡´ ëª¨ë“œ ê²°ê³¼:")
    print(f"   ì´ ì²­í¬ ìˆ˜: {len(old_chunks)}")
    print(f"   í‰ê·  ì²­í¬ í¬ê¸°: {old_stats['avg_chunk_size']:.1f}ì")
    print(f"   ì‘ì€ ì²­í¬ ë¹„ìœ¨: {old_stats['small_chunks_ratio']:.1f}%")
    print(f"   ì²˜ë¦¬ ì‹œê°„: {old_duration:.3f}ì´ˆ")
    print(f"   ì„±ëŠ¥ ë“±ê¸‰: {old_stats.get('performance_grade', 'N/A')}")
    
    # ìƒˆë¡œìš´ ì—„ê²©í•œ ì„¤ì • í…ŒìŠ¤íŠ¸
    print("\n2ï¸âƒ£ ìƒˆë¡œìš´ ì—„ê²©í•œ ì„¤ì • í…ŒìŠ¤íŠ¸")
    new_buffer = ChunkBuffer(buffer_size=300, buffer_timeout=1.0)
    new_buffer.strict_size_enforcement = True
    
    new_chunks = []
    new_start = time.time()
    
    for token in tokens:
        result = new_buffer.add_chunk(token)
        if result:
            new_chunks.append(result)
    
    # ë§ˆì§€ë§‰ í”ŒëŸ¬ì‹œ
    final_new = new_buffer.force_flush()
    if final_new:
        new_chunks.append(final_new)
    
    new_duration = time.time() - new_start
    new_stats = new_buffer.get_performance_stats()
    
    print(f"ğŸ“Š ì—„ê²©í•œ ëª¨ë“œ ê²°ê³¼:")
    print(f"   ì´ ì²­í¬ ìˆ˜: {len(new_chunks)}")
    print(f"   í‰ê·  ì²­í¬ í¬ê¸°: {new_stats['avg_chunk_size']:.1f}ì")
    print(f"   ì‘ì€ ì²­í¬ ë¹„ìœ¨: {new_stats['small_chunks_ratio']:.1f}%")
    print(f"   ìµœì  ì²­í¬ ë¹„ìœ¨: {new_stats['optimal_chunks_ratio']:.1f}%")
    print(f"   ì²˜ë¦¬ ì‹œê°„: {new_duration:.3f}ì´ˆ")
    print(f"   ì„±ëŠ¥ ë“±ê¸‰: {new_stats.get('performance_grade', 'A')}")
    print(f"   ë²„í¼ íš¨ìœ¨ì„±: {new_stats.get('buffer_efficiency', 0):.1f}%")
    
    # ì„±ëŠ¥ ê°œì„  ë¶„ì„
    print("\nğŸ“ˆ ì„±ëŠ¥ ê°œì„  ë¶„ì„:")
    chunk_reduction = ((len(old_chunks) - len(new_chunks)) / len(old_chunks)) * 100
    size_improvement = new_stats['avg_chunk_size'] / old_stats['avg_chunk_size']
    small_chunk_reduction = old_stats['small_chunks_ratio'] - new_stats['small_chunks_ratio']
    
    print(f"   ì²­í¬ ìˆ˜ ê°ì†Œ: {chunk_reduction:.1f}% ({len(old_chunks)} â†’ {len(new_chunks)})")
    print(f"   í‰ê·  í¬ê¸° ì¦ê°€: {size_improvement:.1f}ë°°")
    print(f"   ì‘ì€ ì²­í¬ ê°ì†Œ: {small_chunk_reduction:.1f}%p")
    
    # ì²­í¬ ë‚´ìš© ì˜ˆì‹œ ì¶œë ¥
    print("\nğŸ“‹ ì²­í¬ ë‚´ìš© ì˜ˆì‹œ (ì²˜ìŒ 3ê°œ):")
    for i, chunk in enumerate(new_chunks[:3]):
        print(f"   ì²­í¬ {i+1} ({len(chunk)}ì): {repr(chunk[:50])}...")
    
    # ìƒì„¸ í†µê³„ JSON ì¶œë ¥
    print(f"\nğŸ“„ ìƒì„¸ ì„±ëŠ¥ í†µê³„:")
    print(json.dumps(new_stats, indent=2, ensure_ascii=False))
    
    return {
        'old_chunks': len(old_chunks),
        'new_chunks': len(new_chunks),
        'reduction_percentage': chunk_reduction,
        'new_stats': new_stats
    }

def test_edge_cases():
    """ì—£ì§€ ì¼€ì´ìŠ¤ í…ŒìŠ¤íŠ¸"""
    print("\n\nğŸ”¬ ì—£ì§€ ì¼€ì´ìŠ¤ í…ŒìŠ¤íŠ¸")
    print("=" * 40)
    
    buffer = ChunkBuffer()
    
    # 1. ë¹ˆ ë¬¸ìì—´ í…ŒìŠ¤íŠ¸
    print("1. ë¹ˆ ë¬¸ìì—´ í…ŒìŠ¤íŠ¸")
    result = buffer.add_chunk("")
    print(f"   ê²°ê³¼: {result}")
    
    # 2. íŠ¹ìˆ˜ í† í° í…ŒìŠ¤íŠ¸
    print("2. íŠ¹ìˆ˜ í† í° ì œê±° í…ŒìŠ¤íŠ¸")
    result = buffer.add_chunk("ì½”ë“œ ìƒì„± ì™„ë£Œ<|im_end|>")
    print(f"   ê²°ê³¼: {repr(result)}")
    
    # 3. ë§¤ìš° ê¸´ ë‹¨ì¼ í† í° í…ŒìŠ¤íŠ¸
    print("3. ë§¤ìš° ê¸´ ë‹¨ì¼ í† í° í…ŒìŠ¤íŠ¸")
    long_token = "x" * 1000
    result = buffer.add_chunk(long_token)
    print(f"   ê²°ê³¼ ê¸¸ì´: {len(result) if result else 'None'}")
    
    # 4. ê°•ì œ í”ŒëŸ¬ì‹œ í…ŒìŠ¤íŠ¸
    print("4. ê°•ì œ í”ŒëŸ¬ì‹œ í…ŒìŠ¤íŠ¸")
    buffer.add_chunk("ë¯¸ì™„ì„± ")
    buffer.add_chunk("ì½”ë“œ")
    result = buffer.force_flush()
    print(f"   ê°•ì œ í”ŒëŸ¬ì‹œ ê²°ê³¼: {repr(result)}")

if __name__ == "__main__":
    try:
        # ë©”ì¸ ì„±ëŠ¥ í…ŒìŠ¤íŠ¸
        results = test_chunk_buffer_performance()
        
        # ì—£ì§€ ì¼€ì´ìŠ¤ í…ŒìŠ¤íŠ¸  
        test_edge_cases()
        
        # ìµœì¢… ìš”ì•½
        print(f"\n\nğŸ¯ ìµœì¢… ìš”ì•½:")
        print(f"âœ… ì²­í¬ ìˆ˜ {results['reduction_percentage']:.1f}% ê°ì†Œ ë‹¬ì„±!")
        print(f"âœ… ì„±ëŠ¥ ë“±ê¸‰: {results['new_stats'].get('performance_grade', 'A')}")
        print(f"âœ… ë²„í¼ íš¨ìœ¨ì„±: {results['new_stats'].get('buffer_efficiency', 0):.1f}%")
        
        if results['reduction_percentage'] >= 70:
            print("ğŸ† ëª©í‘œ ë‹¬ì„±: 70% ì´ìƒ ì²­í¬ ê°ì†Œ ì„±ê³µ!")
        else:
            print("âš ï¸ ëª©í‘œ ë¯¸ë‹¬: ì¶”ê°€ ìµœì í™” í•„ìš”")
            
    except Exception as e:
        print(f"âŒ í…ŒìŠ¤íŠ¸ ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜: {e}")
        import traceback
        traceback.print_exc() 