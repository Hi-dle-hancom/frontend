"""
AI ê¸°ë°˜ ì½”ë“œ ìƒì„± API ì—”ë“œí¬ì¸íŠ¸ (Enhanced í†µí•©)
- vLLM ë©€í‹° LoRA ì„œë²„ì™€ í†µí•©
- ì‹¤ì‹œê°„ ìŠ¤íŠ¸ë¦¬ë° ì‘ë‹µ ì§€ì›
- 4ê°€ì§€ ëª¨ë¸ íƒ€ì…ë³„ ìµœì í™”
- í•œêµ­ì–´/ì˜ì–´ ìë™ ë²ˆì—­ íŒŒì´í”„ë¼ì¸
- ğŸ†• Enhanced ê¸°ëŠ¥: ì‚¬ìš©ì ê°œì¸í™”, ë³´ì•ˆ ê²€ì¦, JWT í† í° ì§€ì›
"""

import json
from datetime import datetime
from typing import Any, Dict, Optional, List

from fastapi import APIRouter, BackgroundTasks, Depends, HTTPException, Query, Header, Request
from fastapi.responses import StreamingResponse

from app.core.rate_limiter import limiter
from app.core.security import get_api_key, get_current_user
from app.core.structured_logger import StructuredLogger
from app.schemas.code_generation import (
    CodeGenerationRequest,
    CodeGenerationResponse,
    ModelType,
    CompletionRequest,
    CompletionResponse,
    CompletionSuggestion,
    CompletionStats,
)
from app.services.error_handling_service import error_handling_service
from app.services.vllm_integration_service import vllm_service
from app.services.enhanced_ai_model import enhanced_ai_service

router = APIRouter(prefix="/code", tags=["Code Generation"])
import logging
logger = logging.getLogger("code_generation_api")
structured_logger = StructuredLogger("code_generation_api")

# Enhanced ê¸°ëŠ¥ì„ ìœ„í•œ ì¶”ê°€ import
from app.core.logging_config import setup_logging
from app.core.security import (
    APIKeyModel,
    check_permission,
    check_rate_limit_dependency,
    get_current_api_key,
)

# =============================================================================
# Helper í•¨ìˆ˜ë“¤ êµ¬í˜„ (ëˆ„ë½ëœ í•¨ìˆ˜ë“¤)
# =============================================================================

import httpx
import jwt
from app.core.config import settings

async def decode_jwt_and_get_user_id(access_token: str) -> Optional[str]:
    """JWT í† í°ì—ì„œ ì‚¬ìš©ì ID ì¶”ì¶œ"""
    try:
        # JWT ì‹œí¬ë¦¿ í‚¤ ê°€ì ¸ì˜¤ê¸° (í™˜ê²½ë³€ìˆ˜ ë˜ëŠ” ì„¤ì •ì—ì„œ)
        secret_key = getattr(settings, 'JWT_SECRET_KEY', 'default_secret')
        
        # JWT í† í° ë””ì½”ë”©
        payload = jwt.decode(access_token, secret_key, algorithms=["HS256"])
        
        # ì‚¬ìš©ì ID ì¶”ì¶œ (ì¼ë°˜ì ìœ¼ë¡œ 'sub' ë˜ëŠ” 'user_id' í•„ë“œ)
        user_id = payload.get('sub') or payload.get('user_id')
        
        if user_id:
            logger.info(f"JWT í† í°ì—ì„œ ì‚¬ìš©ì ID ì¶”ì¶œ ì„±ê³µ: {user_id}")
            return str(user_id)
        else:
            logger.warning("JWT í† í°ì— ì‚¬ìš©ì IDê°€ ì—†ìŠµë‹ˆë‹¤")
            return None
            
    except jwt.ExpiredSignatureError:
        logger.warning("JWT í† í°ì´ ë§Œë£Œë˜ì—ˆìŠµë‹ˆë‹¤")
        return None
    except jwt.InvalidTokenError as e:
        logger.warning(f"ìœ íš¨í•˜ì§€ ì•Šì€ JWT í† í°: {e}")
        return None
    except Exception as e:
        logger.error(f"JWT í† í° ë””ì½”ë”© ì¤‘ ì˜¤ë¥˜: {e}")
        return None


async def fetch_user_settings_from_db(user_id: str) -> Optional[Dict[str, Any]]:
    """DB-Moduleì—ì„œ ì‚¬ìš©ì ê°œì¸í™” ì„¤ì • ì¡°íšŒ"""
    try:
        # DB-Module API ì—”ë“œí¬ì¸íŠ¸
        db_module_url = getattr(settings, 'DB_MODULE_URL', 'http://localhost:8001')
        timeout = getattr(settings, 'DB_MODULE_TIMEOUT', 10)
        
        # DB-Moduleì—ì„œ ì‚¬ìš©ì ì„¤ì • ì¡°íšŒ
        async with httpx.AsyncClient() as client:
            response = await client.get(
                f"{db_module_url}/settings/options",
                headers={"Authorization": f"Bearer {user_id}"},  # ì„ì‹œ: user_idë¥¼ í† í°ìœ¼ë¡œ ì‚¬ìš©
                timeout=timeout
            )
            
            if response.status_code == 200:
                settings_data = response.json()
                logger.info(f"DBì—ì„œ ì‚¬ìš©ì ì„¤ì • ì¡°íšŒ ì„±ê³µ: {user_id}")
                return settings_data
            else:
                logger.warning(f"DB ì„¤ì • ì¡°íšŒ ì‹¤íŒ¨: {response.status_code} - {user_id}")
                return None
                
    except httpx.TimeoutException:
        logger.warning(f"DB ì„¤ì • ì¡°íšŒ íƒ€ì„ì•„ì›ƒ: {user_id}")
        return None
    except Exception as e:
        logger.error(f"DB ì„¤ì • ì¡°íšŒ ì¤‘ ì˜¤ë¥˜: {e}")
        return None


def map_db_settings_to_ai_preferences(db_settings: Dict[str, Any]) -> Dict[str, Any]:
    """DB ì„¤ì •ì„ AI ê°œì¸í™” ì„ í˜¸ë„ë¡œ ë§¤í•‘"""
    try:
        # DB ì„¤ì • ì˜µì…˜ì—ì„œ ì‚¬ìš©ì ì„ í˜¸ë„ ì¶”ì¶œ
        options = db_settings.get('options', [])
        
        # ê¸°ë³¸ê°’ ì„¤ì •
        preferences = {
            "safety_level": "standard",
            "code_style": "standard", 
            "skill_level": "intermediate",
            "project_context": "general_purpose"
        }
        
        # DB ì˜µì…˜ì„ AI ì„ í˜¸ë„ë¡œ ë§¤í•‘
        for option in options:
            setting_type = option.get('setting_type', '')
            option_value = option.get('option_value', '')
            
            # Python ìŠ¤í‚¬ ë ˆë²¨ ë§¤í•‘
            if setting_type == 'python_skill_level':
                if option_value in ['beginner', 'intermediate', 'advanced', 'expert']:
                    preferences['skill_level'] = option_value
            
            # ì½”ë“œ ì¶œë ¥ êµ¬ì¡° ë§¤í•‘
            elif setting_type == 'code_output_structure':
                if option_value == 'minimal':
                    preferences['code_style'] = 'concise'
                elif option_value == 'standard':
                    preferences['code_style'] = 'standard'
                elif option_value == 'detailed':
                    preferences['code_style'] = 'detailed'
            
            # ì„¤ëª… ìŠ¤íƒ€ì¼ ë§¤í•‘
            elif setting_type == 'explanation_style':
                if option_value == 'brief':
                    preferences['safety_level'] = 'minimal'
                elif option_value == 'standard':
                    preferences['safety_level'] = 'standard'
                elif option_value in ['detailed', 'educational']:
                    preferences['safety_level'] = 'enhanced'
            
            # í”„ë¡œì íŠ¸ ì»¨í…ìŠ¤íŠ¸ ë§¤í•‘
            elif setting_type == 'project_context':
                if option_value in ['web_development', 'data_science', 'automation', 'general_purpose']:
                    preferences['project_context'] = option_value
        
        logger.info(f"DB ì„¤ì •ì„ AI ì„ í˜¸ë„ë¡œ ë§¤í•‘ ì™„ë£Œ: {preferences}")
        return preferences
        
    except Exception as e:
        logger.error(f"DB ì„¤ì • ë§¤í•‘ ì¤‘ ì˜¤ë¥˜: {e}")
        # ì˜¤ë¥˜ ì‹œ ê¸°ë³¸ê°’ ë°˜í™˜
        return {
            "safety_level": "standard",
            "code_style": "standard", 
            "skill_level": "intermediate",
            "project_context": "general_purpose"
        }


def default_preferences() -> Dict[str, Any]:
    """ê¸°ë³¸ ì‚¬ìš©ì ì„ í˜¸ë„ ë°˜í™˜"""
    return {
        "safety_level": "standard",
        "code_style": "standard", 
        "skill_level": "intermediate",
        "project_context": "general_purpose"
    }


async def _get_user_preferences(
    access_token: Optional[str], 
    user_profile: Optional[Dict[str, Any]], 
    user_id: str
) -> Optional[Dict[str, Any]]:
    """ì‚¬ìš©ì ê°œì¸í™” ì„¤ì • ì¡°íšŒ (ì‹¤ì œ DB ì—°ë™ êµ¬í˜„)"""
    try:
        # 1ë‹¨ê³„: JWT í† í°ì´ ìˆëŠ” ê²½ìš° ì‹¤ì œ DBì—ì„œ ì‚¬ìš©ì ì„¤ì • ì¡°íšŒ
        if access_token:
            # JWT í† í°ì—ì„œ ì‚¬ìš©ì ID ì¶”ì¶œ
            jwt_user_id = await decode_jwt_and_get_user_id(access_token)
            
            if jwt_user_id:
                # DBì—ì„œ ì‚¬ìš©ì ì„¤ì • ì¡°íšŒ
                db_settings = await fetch_user_settings_from_db(jwt_user_id)
                
                if db_settings:
                    # DB ì„¤ì •ì„ AI ì„ í˜¸ë„ë¡œ ë³€í™˜
                    return map_db_settings_to_ai_preferences(db_settings)
                else:
                    logger.info(f"DB ì„¤ì •ì´ ì—†ì–´ ê¸°ë³¸ê°’ ì‚¬ìš©: {jwt_user_id}")
                    return default_preferences()
            else:
                logger.warning("JWT í† í°ì—ì„œ ì‚¬ìš©ì ID ì¶”ì¶œ ì‹¤íŒ¨")
                return default_preferences()
        
        # 2ë‹¨ê³„: userProfileì´ ìˆëŠ” ê²½ìš° í™œìš©
        if user_profile:
            return {
                "safety_level": user_profile.get("safety_level", "standard"),
                "code_style": user_profile.get("code_style", "standard"),
                "skill_level": user_profile.get("skill_level", "intermediate"),
                "project_context": user_profile.get("project_context", "general_purpose")
            }
        
        # 3ë‹¨ê³„: ëª¨ë“  ê°œì¸í™” ì •ë³´ê°€ ì—†ëŠ” ê²½ìš° ê¸°ë³¸ê°’
        logger.info(f"ê°œì¸í™” ì •ë³´ê°€ ì—†ì–´ ê¸°ë³¸ê°’ ì‚¬ìš©: {user_id}")
        return default_preferences()
        
    except Exception as e:
        logger.warning(f"ì‚¬ìš©ì ì„¤ì • ì¡°íšŒ ì‹¤íŒ¨: {e}")
        return default_preferences()


async def _optimize_request_for_user(
    request: CodeGenerationRequest, 
    user_preferences: Dict[str, Any]
) -> CodeGenerationRequest:
    """ì‚¬ìš©ì ì„ í˜¸ë„ì— ë”°ë¥¸ ìš”ì²­ ìµœì í™”"""
    try:
        import copy
        optimized_request = copy.deepcopy(request)
        
        # ìŠ¤í‚¬ ë ˆë²¨ì— ë”°ë¥¸ max_tokens ì¡°ì •
        skill_level = user_preferences.get("skill_level", "intermediate")
        if skill_level == "beginner":
            # ì´ˆê¸‰ì: ë” ìƒì„¸í•œ ì„¤ëª… í•„ìš”
            optimized_request.max_tokens = min(optimized_request.max_tokens * 1.5, 1500)
        elif skill_level == "expert":
            # ì „ë¬¸ê°€: ê°„ê²°í•œ ì½”ë“œ ì„ í˜¸
            optimized_request.max_tokens = max(optimized_request.max_tokens * 0.8, 300)
        
        # ì½”ë“œ ìŠ¤íƒ€ì¼ì— ë”°ë¥¸ temperature ì¡°ì •
        code_style = user_preferences.get("code_style", "standard")
        if code_style == "concise":
            optimized_request.temperature = max(optimized_request.temperature * 0.8, 0.1)
        elif code_style == "detailed":
            optimized_request.temperature = min(optimized_request.temperature * 1.2, 0.4)
        
        # ì•ˆì „ì„± ë ˆë²¨ì— ë”°ë¥¸ top_p ì¡°ì •
        safety_level = user_preferences.get("safety_level", "standard")
        if safety_level == "enhanced":
            optimized_request.top_p = max(optimized_request.top_p * 0.9, 0.7)
        elif safety_level == "minimal":
            optimized_request.top_p = min(optimized_request.top_p * 1.1, 0.95)
        
        logger.info(f"ì‚¬ìš©ì ì„ í˜¸ë„ ê¸°ë°˜ ìš”ì²­ ìµœì í™” ì™„ë£Œ: skill_level={skill_level}, code_style={code_style}")
        return optimized_request
        
    except Exception as e:
        logger.error(f"ìš”ì²­ ìµœì í™” ì¤‘ ì˜¤ë¥˜: {e}")
        return request


def build_personalized_prompt(base_prompt: str, user_preferences: Dict[str, Any]) -> str:
    """ì‚¬ìš©ì ì„ í˜¸ë„ë¥¼ ë°˜ì˜í•œ ê°œì¸í™”ëœ í”„ë¡¬í”„íŠ¸ ìƒì„±"""
    try:
        skill_level = user_preferences.get("skill_level", "intermediate")
        code_style = user_preferences.get("code_style", "standard")
        project_context = user_preferences.get("project_context", "general_purpose")
        safety_level = user_preferences.get("safety_level", "standard")
        
        # ìŠ¤í‚¬ ë ˆë²¨ë³„ ì§€ì‹œì‚¬í•­
        skill_instructions = {
            "beginner": "ì´ˆê¸‰ìë¥¼ ìœ„í•´ ìƒì„¸í•œ ì£¼ì„ê³¼ ì„¤ëª…ì„ í¬í•¨í•˜ì—¬ ë‹¨ê³„ë³„ë¡œ ì„¤ëª…í•´ì£¼ì„¸ìš”.",
            "intermediate": "ì¤‘ê¸‰ì ìˆ˜ì¤€ì— ë§ì¶° ì ì ˆí•œ ì£¼ì„ê³¼ í•¨ê»˜ ì‹¤ìš©ì ì¸ ì½”ë“œë¥¼ ì‘ì„±í•´ì£¼ì„¸ìš”.",
            "advanced": "ê³ ê¸‰ ì‚¬ìš©ìë¥¼ ìœ„í•´ íš¨ìœ¨ì ì´ê³  ìµœì í™”ëœ ì½”ë“œë¥¼ ì‘ì„±í•´ì£¼ì„¸ìš”.",
            "expert": "ì „ë¬¸ê°€ ìˆ˜ì¤€ì— ë§ì¶° ê°„ê²°í•˜ê³  ê³ ì„±ëŠ¥ì˜ ì½”ë“œë¥¼ ì‘ì„±í•´ì£¼ì„¸ìš”."
        }
        
        # ì½”ë“œ ìŠ¤íƒ€ì¼ë³„ ì§€ì‹œì‚¬í•­
        style_instructions = {
            "concise": "ìµœëŒ€í•œ ê°„ê²°í•˜ê³  í•µì‹¬ì ì¸ ì½”ë“œë§Œ ì‘ì„±í•´ì£¼ì„¸ìš”.",
            "standard": "ì¼ë°˜ì ì¸ ì½”ë”© ìŠ¤íƒ€ì¼ë¡œ ê°€ë…ì„± ì¢‹ì€ ì½”ë“œë¥¼ ì‘ì„±í•´ì£¼ì„¸ìš”.",
            "detailed": "ìƒì„¸í•œ ì£¼ì„ê³¼ ì˜ˆì™¸ì²˜ë¦¬ë¥¼ í¬í•¨í•œ ì™„ì „í•œ ì½”ë“œë¥¼ ì‘ì„±í•´ì£¼ì„¸ìš”."
        }
        
        # í”„ë¡œì íŠ¸ ì»¨í…ìŠ¤íŠ¸ë³„ ì§€ì‹œì‚¬í•­
        context_instructions = {
            "web_development": "ì›¹ ê°œë°œ í™˜ê²½ì— ìµœì í™”ëœ ì½”ë“œë¡œ ì‘ì„±í•´ì£¼ì„¸ìš”.",
            "data_science": "ë°ì´í„° ë¶„ì„ ë° ê³¼í•™ ê³„ì‚°ì— ì í•©í•œ ì½”ë“œë¡œ ì‘ì„±í•´ì£¼ì„¸ìš”.",
            "automation": "ìë™í™” ìŠ¤í¬ë¦½íŠ¸ì— ì í•©í•œ ì•ˆì •ì ì¸ ì½”ë“œë¡œ ì‘ì„±í•´ì£¼ì„¸ìš”.",
            "general_purpose": "ë²”ìš©ì ìœ¼ë¡œ ì‚¬ìš©í•  ìˆ˜ ìˆëŠ” ì½”ë“œë¡œ ì‘ì„±í•´ì£¼ì„¸ìš”."
        }
        
        # ê°œì¸í™”ëœ í”„ë¡¬í”„íŠ¸ êµ¬ì„±
        personalization_prefix = f"""[ì‚¬ìš©ì ê°œì¸í™” ì„¤ì •]
- ìŠ¤í‚¬ ë ˆë²¨: {skill_level} ({skill_instructions.get(skill_level, '')})
- ì½”ë“œ ìŠ¤íƒ€ì¼: {code_style} ({style_instructions.get(code_style, '')})
- í”„ë¡œì íŠ¸ ì»¨í…ìŠ¤íŠ¸: {project_context} ({context_instructions.get(project_context, '')})
- ì•ˆì „ì„± ë ˆë²¨: {safety_level}

ìœ„ ì„¤ì •ì„ ë°˜ì˜í•˜ì—¬ ë‹¤ìŒ ìš”ì²­ì— ì‘ë‹µí•´ì£¼ì„¸ìš”:

"""
        
        personalized_prompt = personalization_prefix + base_prompt
        
        logger.info(f"ê°œì¸í™”ëœ í”„ë¡¬í”„íŠ¸ ìƒì„± ì™„ë£Œ: skill_level={skill_level}, style={code_style}")
        return personalized_prompt
        
    except Exception as e:
        logger.error(f"ê°œì¸í™”ëœ í”„ë¡¬í”„íŠ¸ ìƒì„± ì¤‘ ì˜¤ë¥˜: {e}")
        return base_prompt


async def _evaluate_code_quality(
    generated_code: str, 
    user_preferences: Dict[str, Any]
) -> Optional[float]:
    """ìƒì„±ëœ ì½”ë“œì˜ í’ˆì§ˆ ì ìˆ˜ ê³„ì‚°"""
    try:
        if not generated_code or not generated_code.strip():
            return 0.0
            
        score = 0.5  # ê¸°ë³¸ ì ìˆ˜
        
        # ì½”ë“œ ê¸¸ì´ í‰ê°€
        if len(generated_code) > 50:
            score += 0.1
            
        # ì£¼ì„ í¬í•¨ ì—¬ë¶€
        if "#" in generated_code or '"""' in generated_code:
            score += 0.1
            
        # í•¨ìˆ˜/í´ë˜ìŠ¤ ì •ì˜ ì—¬ë¶€  
        if "def " in generated_code or "class " in generated_code:
            score += 0.1
            
        # íƒ€ì… íŒíŠ¸ ì‚¬ìš© ì—¬ë¶€
        if "->" in generated_code or ": " in generated_code:
            score += 0.1
            
        # ì‚¬ìš©ì ì„ í˜¸ë„ ë°˜ì˜
        skill_level = user_preferences.get("skill_level", "intermediate")
        if skill_level == "expert":
            # ì „ë¬¸ê°€ëŠ” ë” ê°„ê²°í•œ ì½”ë“œ ì„ í˜¸
            if len(generated_code.split('\n')) < 20:
                score += 0.1
        elif skill_level == "beginner":
            # ì´ˆê¸‰ìëŠ” ìƒì„¸í•œ ì„¤ëª…ì´ ìˆëŠ” ì½”ë“œ ì„ í˜¸
            if generated_code.count('#') > 2:
                score += 0.1
                
        return min(1.0, score)  # ìµœëŒ€ 1.0ìœ¼ë¡œ ì œí•œ
        
    except Exception as e:
        logger.warning(f"ì½”ë“œ í’ˆì§ˆ í‰ê°€ ì‹¤íŒ¨: {e}")
        return None


def _log_generation_usage(
    user_id: str,
    model_type: str,
    generation_type: str,
    success: bool = True,
    processing_time: float = 0.0,
    enhanced: bool = False,
    has_preferences: bool = False
):
    """ë°±ê·¸ë¼ìš´ë“œì—ì„œ ì‚¬ìš©ëŸ‰ ê¸°ë¡"""
    try:
        logger.info(
            f"ì‚¬ìš©ëŸ‰ ê¸°ë¡: {generation_type}",
            extra={
                "user_id": user_id,
                "model_type": model_type,
                "success": success,
                "processing_time": processing_time,
                "enhanced_mode": enhanced,
                "has_preferences": has_preferences
            }
        )
        
        # ì‹¤ì œ êµ¬í˜„ì—ì„œëŠ” ë°ì´í„°ë² ì´ìŠ¤ë‚˜ ë©”íŠ¸ë¦­ ì‹œìŠ¤í…œì— ê¸°ë¡
        # í˜„ì¬ëŠ” ë¡œê¹…ë§Œ ìˆ˜í–‰
        
    except Exception as e:
        logger.error(f"ì‚¬ìš©ëŸ‰ ê¸°ë¡ ì‹¤íŒ¨: {e}")


def _parse_completion_suggestions(
    generated_code: str,
    request: CompletionRequest
) -> List[CompletionSuggestion]:
    """ìƒì„±ëœ ì½”ë“œë¥¼ ê°œë³„ ì œì•ˆìœ¼ë¡œ ë¶„í• """
    try:
        suggestions = []
        
        if not generated_code or not generated_code.strip():
            return suggestions
            
        # ê°„ë‹¨í•œ êµ¬í˜„: ë¼ì¸ë³„ë¡œ ë¶„í• í•˜ì—¬ ì œì•ˆ ìƒì„±
        lines = generated_code.strip().split('\n')
        
        for i, line in enumerate(lines[:request.max_suggestions]):
            if line.strip():
                suggestion = CompletionSuggestion(
                    text=line.strip(),
                    display_text=line.strip()[:50] + "..." if len(line) > 50 else line.strip(),
                    description=f"AI ì œì•ˆ {i+1}",
                    confidence=max(0.7 - i * 0.1, 0.3),  # ì²« ë²ˆì§¸ ì œì•ˆì´ ê°€ì¥ ì‹ ë¢°ë„ ë†’ìŒ
                    completion_type="inline" if len(line.strip()) < 50 else "block"
                )
                suggestions.append(suggestion)
        
        # ìµœì†Œ 1ê°œ ì œì•ˆì€ ë³´ì¥
        if not suggestions and generated_code.strip():
            suggestions.append(CompletionSuggestion(
                text=generated_code.strip(),
                display_text=generated_code.strip()[:50] + "...",
                description="AI ìƒì„± ì½”ë“œ",
                confidence=0.7,
                completion_type="block"
            ))
            
        return suggestions[:request.max_suggestions]
        
    except Exception as e:
        logger.error(f"ì™„ì„± ì œì•ˆ íŒŒì‹± ì‹¤íŒ¨: {e}")
        return []


def _analyze_completion_context(request: CompletionRequest) -> Dict[str, Any]:
    """ìë™ì™„ì„± ì»¨í…ìŠ¤íŠ¸ ë¶„ì„"""
    try:
        analysis = {
            "context_type": "unknown",
            "in_function": False,
            "in_class": False,
            "indentation_level": 0,
            "last_token": "",
            "expected_completion": "statement"
        }
        
        prefix = request.prefix
        if not prefix:
            return analysis
            
        lines = prefix.split('\n')
        if not lines:
            return analysis
            
        last_line = lines[-1] if lines else ""
        
        # ë“¤ì—¬ì“°ê¸° ë ˆë²¨ ê³„ì‚°
        analysis["indentation_level"] = len(last_line) - len(last_line.lstrip())
        
        # í•¨ìˆ˜/í´ë˜ìŠ¤ ë‚´ë¶€ ì—¬ë¶€ í™•ì¸
        for line in reversed(lines):
            line_stripped = line.strip()
            if line_stripped.startswith("def "):
                analysis["in_function"] = True
                break
            elif line_stripped.startswith("class "):
                analysis["in_class"] = True
                break
                
        # ë§ˆì§€ë§‰ í† í° ì¶”ì¶œ
        tokens = last_line.strip().split()
        if tokens:
            analysis["last_token"] = tokens[-1]
            
        # ì˜ˆìƒ ì™„ì„± íƒ€ì… ì¶”ë¡ 
        if last_line.strip().endswith(":"):
            analysis["expected_completion"] = "block"
        elif last_line.strip().endswith("="):
            analysis["expected_completion"] = "expression"
        elif "(" in last_line and not last_line.strip().endswith(")"):
            analysis["expected_completion"] = "argument"
            
        return analysis
        
    except Exception as e:
        logger.error(f"ì»¨í…ìŠ¤íŠ¸ ë¶„ì„ ì‹¤íŒ¨: {e}")
        return {"context_type": "unknown", "error": str(e)}


def _update_completion_stats(
    user_id: str,
    suggestions_count: int,
    processing_time: float,
    language: str
):
    """ìë™ì™„ì„± í†µê³„ ì—…ë°ì´íŠ¸"""
    try:
        logger.info(
            f"ìë™ì™„ì„± í†µê³„ ì—…ë°ì´íŠ¸",
            extra={
                "user_id": user_id,
                "suggestions_count": suggestions_count,
                "processing_time": processing_time,
                "language": language
            }
        )
        
        # ì‹¤ì œ êµ¬í˜„ì—ì„œëŠ” í†µê³„ ë°ì´í„°ë² ì´ìŠ¤ì— ê¸°ë¡
        # í˜„ì¬ëŠ” ë¡œê¹…ë§Œ ìˆ˜í–‰
        
    except Exception as e:
        logger.error(f"í†µê³„ ì—…ë°ì´íŠ¸ ì‹¤íŒ¨: {e}")


def _apply_performance_optimization(request: CodeGenerationRequest) -> CodeGenerationRequest:
    """
    ğŸš€ ì„±ëŠ¥ ìµœì í™” í•¨ìˆ˜: ìš”ì²­ ë³µì¡ë„ ë¶„ì„ ë° ë™ì  íŒŒë¼ë¯¸í„° ì ìš©
    - ê°„ë‹¨í•œ ìš”ì²­: max_tokens=50, temperature=0.1
    - ì¤‘ê°„ ë³µì¡ë„: max_tokens=200, temperature=0.2  
    - ë³µì¡í•œ ìš”ì²­: max_tokens=500, temperature=0.25
    """
    import re
    import copy
    
    # ìš”ì²­ ë³µì‚¬ë³¸ ìƒì„±
    optimized_request = copy.deepcopy(request)
    
    # ë³µì¡ë„ ë¶„ì„
    prompt_lower = request.prompt.lower()
    char_count = len(request.prompt)
    word_count = len(request.prompt.split())
    
    # ê°„ë‹¨í•œ ìš”ì²­ íŒ¨í„´ ê°ì§€
    simple_patterns = [
        r'(ì¶œë ¥|print|display).*["\']?\w{1,10}["\']?',  # "jay ì¶œë ¥"
        r'["\']?\w{1,10}["\']?.*ì¶œë ¥',                 # "jayë¥¼ ì¶œë ¥"
        r'print\s*\(["\']?\w{1,20}["\']?\)',           # print("jay")
        r'^[a-zA-Z_]\w*\s*=\s*["\']?\w{1,20}["\']?$',  # name = "jay"
        r'^\w+\(\)$',                                  # func()
        r'^.{1,50}$',                                  # 50ì ì´í•˜
    ]
    
    # ë³µì¡í•œ ìš”ì²­ íŒ¨í„´ ê°ì§€
    complex_patterns = [
        r'(class|def|async def)',
        r'(algorithm|ì•Œê³ ë¦¬ì¦˜)',
        r'(database|ë°ì´í„°ë² ì´ìŠ¤|db)',
        r'(api|rest|graphql)',
        r'(optimization|ìµœì í™”)',
        r'(machine learning|ë¨¸ì‹ ëŸ¬ë‹|ml)',
        r'(error handling|ì˜ˆì™¸ì²˜ë¦¬)',
        r'(unit test|í…ŒìŠ¤íŠ¸)',
    ]
    
    # íŒ¨í„´ ë§¤ì¹­
    simple_matches = sum(1 for pattern in simple_patterns if re.search(pattern, request.prompt, re.IGNORECASE))
    complex_matches = sum(1 for pattern in complex_patterns if re.search(pattern, request.prompt, re.IGNORECASE))
    
    # ë³µì¡ë„ ê²°ì • ë° íŒŒë¼ë¯¸í„° ìµœì í™”
    if simple_matches > 0 and char_count <= 50 and complex_matches == 0:
        # ê°„ë‹¨í•œ ìš”ì²­: ê·¹í•œ ìµœì í™”
        optimized_request.max_tokens = 50      # 95% ê°ì†Œ
        optimized_request.temperature = 0.1    # ì •í™•ì„± ìš°ì„ 
        optimized_request.top_p = 0.8          # ì§‘ì¤‘ë„ ì¦ê°€
        
        # ê°„ê²°í•œ í”„ë¡¬í”„íŠ¸ë¡œ êµì²´
        if re.search(r'(ì¶œë ¥|print)', request.prompt, re.IGNORECASE):
            optimized_request.prompt = f"""ë‹¤ìŒ ìš”ì²­ì— ëŒ€í•´ Python ì½”ë“œ í•œ ì¤„ë§Œ ì‘ì„±í•˜ì„¸ìš”. ì„¤ëª…ì´ë‚˜ ì£¼ì„ ì—†ì´ ì½”ë“œë§Œ ë°˜í™˜í•˜ì„¸ìš”.

ìš”ì²­: {request.prompt}

ì¡°ê±´:
- í•œ ì¤„ ì½”ë“œë§Œ ì‘ì„±
- print() í•¨ìˆ˜ ì‚¬ìš©
- ì„¤ëª… ê¸ˆì§€
- ì˜ˆì‹œë‚˜ ì¶”ê°€ ë‚´ìš© ê¸ˆì§€

ì½”ë“œ:"""
        
        logger.info(f"ğŸš€ ê°„ë‹¨í•œ ìš”ì²­ ìµœì í™” ì ìš©: max_tokens={optimized_request.max_tokens}, temp={optimized_request.temperature}")
        
    elif complex_matches > 0 or char_count > 200 or word_count > 30:
        # ë³µì¡í•œ ìš”ì²­: ë³´ìˆ˜ì  ìµœì í™”
        optimized_request.max_tokens = 500     # 51% ê°ì†Œ
        optimized_request.temperature = 0.25   # ì•½ê°„ ê°ì†Œ
        optimized_request.top_p = 0.9          # ì•½ê°„ ê°ì†Œ
        
        logger.info(f"ğŸ”§ ë³µì¡í•œ ìš”ì²­ ìµœì í™” ì ìš©: max_tokens={optimized_request.max_tokens}, temp={optimized_request.temperature}")
        
    else:
        # ì¤‘ê°„ ë³µì¡ë„: ì ë‹¹í•œ ìµœì í™”
        optimized_request.max_tokens = 200     # 80% ê°ì†Œ
        optimized_request.temperature = 0.2    # ê°ì†Œ
        optimized_request.top_p = 0.85         # ê°ì†Œ
        
        # ê°„ê²°ì„± ê°•ì œ í”„ë¡¬í”„íŠ¸ ì¶”ê°€
        optimized_request.prompt = f"""ë‹¤ìŒ ìš”ì²­ì— ëŒ€í•´ ê°„ê²°í•˜ê³  ì‹¤ìš©ì ì¸ Python ì½”ë“œë¥¼ ì‘ì„±í•˜ì„¸ìš”.

ìš”ì²­: {request.prompt}

ì¡°ê±´:
- í•µì‹¬ ê¸°ëŠ¥ë§Œ êµ¬í˜„
- ê³¼ë„í•œ ì„¤ëª… ê¸ˆì§€
- ìµœëŒ€í•œ ê°„ê²°í•˜ê²Œ

ì½”ë“œ:"""
        
        logger.info(f"âš–ï¸ ì¤‘ê°„ ë³µì¡ë„ ìµœì í™” ì ìš©: max_tokens={optimized_request.max_tokens}, temp={optimized_request.temperature}")
    
    return optimized_request


# =============================================================================
# ê¸°ì¡´ ì—”ë“œí¬ì¸íŠ¸ ì½”ë“œëŠ” ê·¸ëŒ€ë¡œ ìœ ì§€
# =============================================================================


@router.get("/models", summary="ì‚¬ìš© ê°€ëŠ¥í•œ AI ëª¨ë¸ ëª©ë¡")
@limiter.limit("30/minute")
async def get_available_models(api_key: str = Depends(get_api_key)):
    """
    vLLM ì„œë²„ì—ì„œ ì‚¬ìš© ê°€ëŠ¥í•œ AI ëª¨ë¸ë“¤ì˜ ëª©ë¡ì„ ì¡°íšŒí•©ë‹ˆë‹¤.

    **ì§€ì›í•˜ëŠ” ëª¨ë¸ íƒ€ì…:**
    - `autocomplete`: ì½”ë“œ ìë™ì™„ì„± (ë²ˆì—­ ì—†ìŒ, ì˜ì–´ ì…ë ¥ ê¶Œì¥)
    - `prompt`: ì¼ë°˜ ì½”ë“œ ìƒì„± (ì „ì²´ ë²ˆì—­)
    - `comment`: ì£¼ì„/docstring ìƒì„± (ì£¼ì„ë§Œ ë²ˆì—­)
    - `error_fix`: ë²„ê·¸ ìˆ˜ì • (ì „ì²´ ë²ˆì—­)
    
    **ğŸ†• Enhanced ëª¨ë“œ:** enhanced=true íŒŒë¼ë¯¸í„°ë¡œ ê°œì¸í™” ë° ë³´ì•ˆ ê¸°ëŠ¥ í™œì„±í™”
    """
    try:
        # vLLM ì„œë²„ ìƒíƒœ í™•ì¸
        health_status = await vllm_service.check_health()
        if health_status["status"] != "healthy":
            logger.warning(
                "vLLM ì„œë²„ ìƒíƒœ ë¶ˆì•ˆì •", extra={"health_status": health_status}
            )

        # ì‚¬ìš© ê°€ëŠ¥í•œ ëª¨ë¸ ì¡°íšŒ
        models_info = await vllm_service.get_available_models()

        # HAPA ëª¨ë¸ íƒ€ì…ê³¼ ë§¤í•‘ ì •ë³´ ì¶”ê°€
        hapa_model_mapping = {
            "autocomplete": {
                "hapa_types": ["CODE_COMPLETION"],
                "description": "ì½”ë“œ ìë™ì™„ì„± (ì˜ì–´ ì…ë ¥ ê¶Œì¥)",
                "translation": "ì—†ìŒ",
                "enhanced_features": ["ë³´ì•ˆ ê²€ì¦", "ê°œì¸í™” ì œì•ˆ"],
            },
            "prompt": {
                "hapa_types": [
                    "CODE_GENERATION",
                    "CODE_OPTIMIZATION",
                    "UNIT_TEST_GENERATION",
                ],
                "description": "ì¼ë°˜ ì½”ë“œ ìƒì„±",
                "translation": "ì „ì²´ ë²ˆì—­",
                "enhanced_features": ["ì‚¬ìš©ì ë§ì¶¤ ìŠ¤íƒ€ì¼", "ë³´ì•ˆ ê²€ì¦", "í’ˆì§ˆ í‰ê°€"],
            },
            "comment": {
                "hapa_types": [
                    "CODE_EXPLANATION",
                    "CODE_REVIEW",
                    "DOCUMENTATION"],
                "description": "ì£¼ì„/ë¬¸ì„œ ìƒì„±",
                "translation": "ì£¼ì„ë§Œ ë²ˆì—­",
                "enhanced_features": ["ìŠ¤í‚¬ ë ˆë²¨ë³„ ì„¤ëª…", "í”„ë¡œì íŠ¸ ì»¨í…ìŠ¤íŠ¸"],
            },
            "error_fix": {
                "hapa_types": ["BUG_FIX"],
                "description": "ë²„ê·¸ ìˆ˜ì •",
                "translation": "ì „ì²´ ë²ˆì—­",
                "enhanced_features": ["ì•ˆì „í•œ ìˆ˜ì • ì œì•ˆ", "í…ŒìŠ¤íŠ¸ ì½”ë“œ í¬í•¨"],
            },
        }

        result = {
            "vllm_server_status": health_status["status"],
            "available_models": models_info.get("available_models", []),
            "model_mapping": hapa_model_mapping,
            "server_info": models_info,
            "enhanced_features": {
                "personalization": "ì‚¬ìš©ì í”„ë¡œí•„ ê¸°ë°˜ ë§ì¶¤í™”",
                "security_validation": "ì…ë ¥/ì¶œë ¥ ì•ˆì „ì„± ê²€ì¦",
                "jwt_support": "JWT í† í° ê¸°ë°˜ ê°œì¸í™”",
                "quality_scoring": "ì½”ë“œ í’ˆì§ˆ í‰ê°€",
            },
            "timestamp": datetime.now().isoformat(),
        }

        logger.info(f"ëª¨ë¸ ëª©ë¡ ì¡°íšŒ ì„±ê³µ: {len(result['available_models'])}ê°œ")
        return result

    except Exception as e:
        logger.error(f"ëª¨ë¸ ëª©ë¡ ì¡°íšŒ ì‹¤íŒ¨: {e}")
        raise HTTPException(
            status_code=500, detail="ëª¨ë¸ ëª©ë¡ì„ ì¡°íšŒí•˜ëŠ” ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤"
        )


@router.post("/generate/stream", summary="ì‹¤ì‹œê°„ ìŠ¤íŠ¸ë¦¬ë° ì½”ë“œ ìƒì„± (Enhanced í†µí•©)")
@limiter.limit("20/minute")
async def generate_code_stream(
    request: CodeGenerationRequest,
    background_tasks: BackgroundTasks,
    enhanced: bool = Query(False, description="Enhanced ëª¨ë“œ í™œì„±í™” (ê°œì¸í™”+ë³´ì•ˆ)"),
    authorization: str = Header(None, description="JWT Bearer í† í° (Enhanced ëª¨ë“œ ì „ìš©)"),
    http_request: Request = None,
    api_key: str = Depends(get_api_key),
    current_user: Dict[str, Any] = Depends(get_current_user),
):
    """
    vLLM ì„œë²„ë¥¼ í†µí•´ ì‹¤ì‹œê°„ ìŠ¤íŠ¸ë¦¬ë°ìœ¼ë¡œ ì½”ë“œë¥¼ ìƒì„±í•©ë‹ˆë‹¤.

    **ì§€ì› ê¸°ëŠ¥:**
    - ğŸ”„ **ì‹¤ì‹œê°„ ìŠ¤íŠ¸ë¦¬ë°**: Server-Sent Events í˜•ì‹ìœ¼ë¡œ ì ì§„ì  ì‘ë‹µ
    - ğŸŒ **ìë™ ë²ˆì—­**: ëª¨ë¸ë³„ í•œêµ­ì–´â†’ì˜ì–´ ë²ˆì—­ ì „ëµ
    - ğŸ“Š **ëª¨ë¸ ìµœì í™”**: ìš”ì²­ íƒ€ì…ì— ë”°ë¥¸ í”„ë¡¬í”„íŠ¸ ìµœì í™”
    - ğŸ“Š **ìƒì„¸ ë¡œê¹…**: ìš”ì²­ ì¶”ì  ë° ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§
    
    **ğŸ†• Enhanced ê¸°ëŠ¥ (enhanced=true):**
    - ğŸ‘¤ **ì‚¬ìš©ì ê°œì¸í™”**: JWT í† í° ê¸°ë°˜ ë§ì¶¤í˜• ì½”ë“œ ìƒì„±
    - ğŸ”’ **ë³´ì•ˆ ê²€ì¦**: ì…ë ¥/ì¶œë ¥ ì•ˆì „ì„± ê²€ì‚¬
    - ğŸ“ˆ **í’ˆì§ˆ í‰ê°€**: ìƒì„± ì½”ë“œ í’ˆì§ˆ ì ìˆ˜
    - ğŸ¨ **ìŠ¤íƒ€ì¼ ì ìš©**: ì‚¬ìš©ì ì„ í˜¸ ì½”ë”© ìŠ¤íƒ€ì¼

    **ì‘ë‹µ í˜•ì‹:**
    - Content-Type: `text/event-stream`
    - ê° ë°ì´í„° ì²­í¬: `data: <json_data>\\n\\n`
    - ìŠ¤íŠ¸ë¦¼ ì¢…ë£Œ: `data: [DONE]\\n\\n`
    """

    user_id = current_user.get("user_id", "anonymous")
    
    # Enhanced ëª¨ë“œ ì„¤ì •
    user_preferences = None
    access_token = None
    
    if enhanced:
        # JWT í† í° ì¶”ì¶œ
        if authorization and authorization.startswith("Bearer "):
            access_token = authorization.split(" ")[1]
        
        # ì‚¬ìš©ì ê°œì¸í™” ì„¤ì • ì¡°íšŒ
        user_preferences = await _get_user_preferences(
            access_token, 
            getattr(http_request, 'userProfile', None) if http_request else None,
            user_id
        )

    try:
        # ìš”ì²­ ë¡œê¹… (Enhanced ì •ë³´ í¬í•¨)
        logger.info(
            f"{'Enhanced ' if enhanced else ''}ìŠ¤íŠ¸ë¦¬ë° ì½”ë“œ ìƒì„± ìš”ì²­",
            extra={
                "user_id": user_id,
                "model_type": request.model_type.value,
                "prompt_length": len(request.prompt),
                "has_context": bool(request.context),
                "enhanced_mode": enhanced,
                "has_jwt_token": bool(access_token),
                "user_preferences": user_preferences is not None,
            },
        )

        # vLLM ì„œë²„ ìƒíƒœ í™•ì¸
        health_status = await vllm_service.check_health()
        if health_status["status"] != "healthy":
            raise HTTPException(
                status_code=503,
                detail=f"vLLM ì„œë²„ê°€ ì‚¬ìš© ë¶ˆê°€ëŠ¥í•©ë‹ˆë‹¤: {health_status.get('error', 'Unknown error')}",
            )

        # Enhanced ëª¨ë“œì—ì„œ ë³´ì•ˆ ê²€ì¦
        if enhanced and user_preferences:
            safety_level = user_preferences.get("safety_level", "standard")
            if safety_level in ["strict", "enhanced"]:
                # ì…ë ¥ ì•ˆì „ì„± ê²€ì¦ (Enhanced AI ì„œë¹„ìŠ¤ ì‚¬ìš©)
                try:
                    await enhanced_ai_service.initialize()
                    # ë³´ì•ˆ ê²€ì¦ ë¡œì§ì€ ì„ íƒì ìœ¼ë¡œ ì ìš©
                    logger.info(f"Enhanced ë³´ì•ˆ ê²€ì¦ í™œì„±í™”: {safety_level}")
                except Exception as e:
                    logger.warning(f"Enhanced AI ì„œë¹„ìŠ¤ ì´ˆê¸°í™” ì‹¤íŒ¨, ê¸°ë³¸ ëª¨ë“œë¡œ ì§„í–‰: {e}")

        # ìŠ¤íŠ¸ë¦¬ë° ì‘ë‹µ ìƒì„±
        async def stream_generator():
            try:
                # Enhanced ëª¨ë“œì—ì„œëŠ” ê°œì¸í™”ëœ í”„ë¡¬í”„íŠ¸ ì ìš©
                if enhanced and user_preferences:
                    # ì‚¬ìš©ì ì„ í˜¸ë„ì— ë”°ë¥¸ ìš”ì²­ ìµœì í™”
                    optimized_request = await _optimize_request_for_user(request, user_preferences)
                    # vLLM ì„œë¹„ìŠ¤ì— ê°œì¸í™” ì •ë³´ ì „ë‹¬
                    async for chunk in vllm_service.generate_code_streaming(optimized_request, user_id, user_preferences):
                        # vLLMì—ì„œ ì´ë¯¸ ê°œì¸í™” ë©”íƒ€ë°ì´í„°ê°€ í¬í•¨ë˜ì–´ ìˆìŒ
                        yield f"data: {json.dumps(chunk)}\n\n"
                else:
                    # ğŸš€ ê¸°ë³¸ ëª¨ë“œì—ì„œë„ ìµœì í™” ì ìš© (ë³µì¡ë„ ë¶„ì„ + ë™ì  íŒŒë¼ë¯¸í„°)
                    optimized_request = _apply_performance_optimization(request)
                    async for chunk in vllm_service.generate_code_streaming(optimized_request, user_id):
                        yield f"data: {json.dumps(chunk)}\n\n"

            except Exception as e:
                error_msg = f"ìŠ¤íŠ¸ë¦¬ë° ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}"
                logger.error(error_msg, extra={"user_id": user_id, "enhanced_mode": enhanced})

                # ì˜¤ë¥˜ë¥¼ ìŠ¤íŠ¸ë¦¼ìœ¼ë¡œ ì „ì†¡
                error_data = json.dumps({"error": error_msg, "enhanced_mode": enhanced})
                yield f"data: {error_data}\n\n"
                yield f"data: [DONE]\n\n"

        # ë°±ê·¸ë¼ìš´ë“œ íƒœìŠ¤í¬ë¡œ ì‚¬ìš©ëŸ‰ ê¸°ë¡ (Enhanced ì •ë³´ í¬í•¨)
        background_tasks.add_task(
            _log_generation_usage,
            user_id,
            request.model_type.value,
            "streaming",
            enhanced=enhanced,
            has_preferences=user_preferences is not None
        )

        return StreamingResponse(
            stream_generator(),
            media_type="text/event-stream",
            headers={
                "Cache-Control": "no-cache",
                "Connection": "keep-alive",
                "Access-Control-Allow-Origin": "*",
                "Access-Control-Allow-Headers": "*",
                "X-Enhanced-Mode": "true" if enhanced else "false",
            },
        )

    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"ìŠ¤íŠ¸ë¦¬ë° ì½”ë“œ ìƒì„± ì‹¤íŒ¨: {e}", extra={"user_id": user_id, "enhanced_mode": enhanced})
        raise HTTPException(
            status_code=500, detail="ì½”ë“œ ìƒì„± ì¤‘ ì˜ˆìƒì¹˜ ëª»í•œ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤"
        )


@router.post(
    "/generate", response_model=CodeGenerationResponse, summary="ë™ê¸°ì‹ ì½”ë“œ ìƒì„± (Enhanced í†µí•©)"
)
@limiter.limit("15/minute")
async def generate_code(
    request: CodeGenerationRequest,
    background_tasks: BackgroundTasks,
    enhanced: bool = Query(False, description="Enhanced ëª¨ë“œ í™œì„±í™” (ê°œì¸í™”+ë³´ì•ˆ)"),
    authorization: str = Header(None, description="JWT Bearer í† í° (Enhanced ëª¨ë“œ ì „ìš©)"),
    http_request: Request = None,
    api_key: str = Depends(get_api_key),
    current_user: Dict[str, Any] = Depends(get_current_user),
):
    """
    vLLM ì„œë²„ë¥¼ í†µí•´ ë™ê¸°ì‹ìœ¼ë¡œ ì½”ë“œë¥¼ ìƒì„±í•©ë‹ˆë‹¤.

    **íŠ¹ì§•:**
    - ì™„ì „í•œ ì‘ë‹µì„ í•œ ë²ˆì— ë°˜í™˜
    - ëª¨ë“  ìŠ¤íŠ¸ë¦¬ë° ë°ì´í„°ë¥¼ ìˆ˜ì§‘í•˜ì—¬ ì¢…í•©
    - ìƒì„¸í•œ ë©”íƒ€ë°ì´í„° í¬í•¨
    - ì˜¤ë¥˜ ì²˜ë¦¬ ë° ë³µêµ¬ ì§€ì›
    
    **ğŸ†• Enhanced ê¸°ëŠ¥ (enhanced=true):**
    - ğŸ‘¤ **ì‚¬ìš©ì ê°œì¸í™”**: JWT í† í° ê¸°ë°˜ ë§ì¶¤í˜• ì½”ë“œ ìƒì„±
    - ğŸ”’ **ë³´ì•ˆ ê²€ì¦**: ì…ë ¥/ì¶œë ¥ ì•ˆì „ì„± ê²€ì‚¬
    - ğŸ“ˆ **í’ˆì§ˆ í‰ê°€**: ìƒì„± ì½”ë“œ í’ˆì§ˆ ì ìˆ˜
    - ğŸ¨ **ìŠ¤íƒ€ì¼ ì ìš©**: ì‚¬ìš©ì ì„ í˜¸ ì½”ë”© ìŠ¤íƒ€ì¼
    """

    user_id = current_user.get("user_id", "anonymous")
    start_time = datetime.now()
    
    # Enhanced ëª¨ë“œ ì„¤ì •
    user_preferences = None
    access_token = None
    quality_score = None
    
    if enhanced:
        # JWT í† í° ì¶”ì¶œ
        if authorization and authorization.startswith("Bearer "):
            access_token = authorization.split(" ")[1]
        
        # ì‚¬ìš©ì ê°œì¸í™” ì„¤ì • ì¡°íšŒ
        user_preferences = await _get_user_preferences(
            access_token, 
            getattr(http_request, 'userProfile', None) if http_request else None,
            user_id
        )

    try:
        # ìš”ì²­ ë¡œê¹… (Enhanced ì •ë³´ í¬í•¨)
        logger.info(
            f"{'Enhanced ' if enhanced else ''}ë™ê¸°ì‹ ì½”ë“œ ìƒì„± ìš”ì²­",
            extra={
                "user_id": user_id,
                "model_type": request.model_type.value,
                "prompt_length": len(request.prompt),
                "enhanced_mode": enhanced,
                "has_jwt_token": bool(access_token),
                "user_preferences": user_preferences is not None,
            },
        )

        # vLLM ì„œë²„ ìƒíƒœ í™•ì¸
        health_status = await vllm_service.check_health()
        if health_status["status"] != "healthy":
            return CodeGenerationResponse(
                success=False,
                generated_code="",
                error_message=f"vLLM ì„œë²„ ì‚¬ìš© ë¶ˆê°€: {health_status.get('error', 'Unknown error')}",
                model_used="N/A",
                processing_time=0,
                token_usage={"total_tokens": 0},
            )

        # Enhanced ëª¨ë“œì—ì„œ ë³´ì•ˆ ê²€ì¦
        if enhanced and user_preferences:
            safety_level = user_preferences.get("safety_level", "standard")
            if safety_level in ["strict", "enhanced"]:
                try:
                    await enhanced_ai_service.initialize()
                    logger.info(f"Enhanced ë³´ì•ˆ ê²€ì¦ í™œì„±í™”: {safety_level}")
                except Exception as e:
                    logger.warning(f"Enhanced AI ì„œë¹„ìŠ¤ ì´ˆê¸°í™” ì‹¤íŒ¨, ê¸°ë³¸ ëª¨ë“œë¡œ ì§„í–‰: {e}")

        # ì½”ë“œ ìƒì„± ì‹¤í–‰ (Enhanced ê°œì¸í™” ì ìš©)
        if enhanced and user_preferences:
            # ì‚¬ìš©ì ì„ í˜¸ë„ì— ë”°ë¥¸ ìš”ì²­ ìµœì í™”
            optimized_request = await _optimize_request_for_user(request, user_preferences)
            response = await vllm_service.generate_code_sync(optimized_request, user_id, user_preferences)
            
            # Enhanced ëª¨ë“œì—ì„œ í’ˆì§ˆ í‰ê°€
            quality_score = await _evaluate_code_quality(response.generated_code, user_preferences)
        else:
            # ğŸš€ ê¸°ë³¸ ëª¨ë“œì—ì„œë„ ìµœì í™” ì ìš© (ë³µì¡ë„ ë¶„ì„ + ë™ì  íŒŒë¼ë¯¸í„°)
            optimized_request = _apply_performance_optimization(request)
            response = await vllm_service.generate_code_sync(optimized_request, user_id)

        # ì²˜ë¦¬ ì‹œê°„ ê³„ì‚°
        processing_time = (datetime.now() - start_time).total_seconds()
        response.processing_time = processing_time

        # Enhanced ë©”íƒ€ë°ì´í„° ì¶”ê°€
        if enhanced and response.success:
            # ì‘ë‹µì— Enhanced ì •ë³´ ì¶”ê°€
            if not hasattr(response, 'metadata'):
                response.metadata = {}
            
            response.metadata.update({
                "enhanced_mode": True,
                "personalized": user_preferences is not None,
                "safety_level": user_preferences.get("safety_level", "standard") if user_preferences else "standard",
                "user_style": user_preferences.get("code_style", "standard") if user_preferences else "standard",
                "quality_score": quality_score,
                "skill_level": user_preferences.get("skill_level", "intermediate") if user_preferences else "intermediate"
            })

        # ì„±ê³µ ë¡œê¹… (Enhanced ì •ë³´ í¬í•¨)
        if response.success:
            logger.info(
                f"{'Enhanced ' if enhanced else ''}ì½”ë“œ ìƒì„± ì„±ê³µ",
                extra={
                    "user_id": user_id,
                    "model_used": response.model_used,
                    "processing_time": processing_time,
                    "output_length": len(response.generated_code),
                    "enhanced_mode": enhanced,
                    "quality_score": quality_score,
                    "personalized": user_preferences is not None,
                },
            )
        else:
            logger.warning(
                f"{'Enhanced ' if enhanced else ''}ì½”ë“œ ìƒì„± ì‹¤íŒ¨",
                extra={
                    "user_id": user_id,
                    "error": response.error_message,
                    "processing_time": processing_time,
                    "enhanced_mode": enhanced,
                },
            )

        # ë°±ê·¸ë¼ìš´ë“œ íƒœìŠ¤í¬ë¡œ ì‚¬ìš©ëŸ‰ ê¸°ë¡ (Enhanced ì •ë³´ í¬í•¨)
        background_tasks.add_task(
            _log_generation_usage,
            user_id,
            request.model_type.value,
            "sync",
            response.success,
            processing_time,
            enhanced=enhanced,
            has_preferences=user_preferences is not None,
        )

        return response

    except Exception as e:
        processing_time = (datetime.now() - start_time).total_seconds()
        error_msg = f"ë™ê¸°ì‹ ì½”ë“œ ìƒì„± ì‹¤íŒ¨: {str(e)}"

        logger.error(
            error_msg,
            extra={
                "user_id": user_id,
                "processing_time": processing_time,
                "exception": str(e),
            },
        )

        # ì˜¤ë¥˜ ì‘ë‹µ ë°˜í™˜
        return CodeGenerationResponse(
            success=False,
            generated_code="",
            error_message="ì½”ë“œ ìƒì„± ì¤‘ ì˜ˆìƒì¹˜ ëª»í•œ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤",
            model_used="N/A",
            processing_time=processing_time,
            token_usage={"total_tokens": 0},
        )


@router.get("/health", summary="vLLM ì„œë²„ ìƒíƒœ í™•ì¸")
async def check_vllm_health(api_key: str = Depends(get_api_key)):
    """
    vLLM ë©€í‹° LoRA ì„œë²„ì˜ ìƒíƒœë¥¼ í™•ì¸í•©ë‹ˆë‹¤.

    **ë°˜í™˜ ì •ë³´:**
    - ì„œë²„ ìƒíƒœ (healthy/unhealthy/error)
    - ì‘ë‹µ ì‹œê°„
    - ì‚¬ìš© ê°€ëŠ¥í•œ ëª¨ë¸ ëª©ë¡
    - ì„œë²„ ì„¸ë¶€ ì •ë³´
    """
    try:
        health_status = await vllm_service.check_health()
        models_info = await vllm_service.get_available_models()

        return {
            "vllm_server": health_status,
            "available_models": models_info.get("available_models", []),
            "server_details": models_info,
            "timestamp": datetime.now().isoformat(),
            "integration_status": "active",
        }

    except Exception as e:
        logger.error(f"vLLM ìƒíƒœ í™•ì¸ ì‹¤íŒ¨: {e}")
        return {
            "vllm_server": {"status": "error", "error": str(e)},
            "available_models": [],
            "server_details": {},
            "timestamp": datetime.now().isoformat(),
            "integration_status": "error",
        }


@router.post("/test", summary="vLLM ì—°ë™ í…ŒìŠ¤íŠ¸")
@limiter.limit("5/minute")
async def test_vllm_integration(
    model_type: ModelType = Query(
        ModelType.CODE_GENERATION, description="í…ŒìŠ¤íŠ¸í•  ëª¨ë¸ íƒ€ì…"
    ),
    api_key: str = Depends(get_api_key),
    current_user: Dict[str, Any] = Depends(get_current_user),
):
    """
    vLLM ì„œë²„ì™€ì˜ ì—°ë™ì„ í…ŒìŠ¤íŠ¸í•©ë‹ˆë‹¤.

    **í…ŒìŠ¤íŠ¸ ë‚´ìš©:**
    - ê°„ë‹¨í•œ ì½”ë“œ ìƒì„± ìš”ì²­
    - ì‘ë‹µ ì‹œê°„ ì¸¡ì •
    - ì˜¤ë¥˜ ì²˜ë¦¬ ê²€ì¦
    """

    user_id = current_user.get("user_id", "test_user")

    # í…ŒìŠ¤íŠ¸ ìš”ì²­ ìƒì„±
    test_request = CodeGenerationRequest(
        prompt="íŒŒì´ì¬ìœ¼ë¡œ Hello Worldë¥¼ ì¶œë ¥í•˜ëŠ” ê°„ë‹¨í•œ í•¨ìˆ˜ë¥¼ ë§Œë“¤ì–´ì£¼ì„¸ìš”.",
        model_type=model_type,
        context="",
        max_tokens=100,
        temperature=0.3,
    )

    try:
        start_time = datetime.now()

        # ë™ê¸°ì‹ ìƒì„± í…ŒìŠ¤íŠ¸
        response = await vllm_service.generate_code_sync(test_request, user_id)

        processing_time = (datetime.now() - start_time).total_seconds()

        test_result = {
            "test_status": "success" if response.success else "failed",
            "response_time_seconds": processing_time,
            "model_used": response.model_used,
            "output_length": len(
                response.generated_code) if response.success else 0,
            "error_message": response.error_message if not response.success else None,
            "timestamp": datetime.now().isoformat(),
        }

        logger.info(f"vLLM ì—°ë™ í…ŒìŠ¤íŠ¸ ì™„ë£Œ", extra=test_result)
        return test_result

    except Exception as e:
        error_result = {
            "test_status": "error",
            "error_message": str(e),
            "timestamp": datetime.now().isoformat(),
        }

        logger.error(f"vLLM ì—°ë™ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {e}")
        return error_result


@router.post("/complete", response_model=CompletionResponse, summary="ì½”ë“œ ìë™ ì™„ì„±")
@limiter.limit("50/minute")
async def complete_code(
    request: CompletionRequest,
    background_tasks: BackgroundTasks,
    api_key: str = Depends(get_api_key),
    current_user: Dict[str, Any] = Depends(get_current_user),
):
    """
    ì½”ë“œ ìë™ ì™„ì„± API

    **íŠ¹ì§•:**
    - ğŸ¯ **ì»¤ì„œ ìœ„ì¹˜ ê¸°ë°˜ ì™„ì„±**: prefix/suffix ê¸°ë°˜ ì •í™•í•œ ì»¨í…ìŠ¤íŠ¸ ë¶„ì„
    - ğŸš€ **ë¹ ë¥¸ ì‘ë‹µ**: í‰ê·  500ms ì´ë‚´ ì‘ë‹µ
    - ğŸ§  **ì§€ëŠ¥í˜• ì œì•ˆ**: vLLM autocomplete ëª¨ë¸ í™œìš©
    - ğŸ“š **íƒ€ì… ì¸ì‹**: Python íƒ€ì… íŒíŠ¸ ê¸°ë°˜ ì œì•ˆ
    - ğŸ” **ë‹¤ì¤‘ ì œì•ˆ**: ìµœëŒ€ 20ê°œ ì™„ì„± ì˜µì…˜

    **ì…ë ¥ ì˜ˆì‹œ:**
    ```json
    {
        "prefix": "def calculate_fibonacci(n: int) -> int:\n    if n <= 1:\n        return ",
        "suffix": "\n    return calculate_fibonacci(n-1) + calculate_fibonacci(n-2)",
        "language": "python",
        "max_suggestions": 5
    }
    ```
    """
    
    user_id = current_user.get("user_id", "anonymous")
    start_time = datetime.now()
    
    try:
        # ìš”ì²­ ë¡œê¹…
        logger.info(
            f"ì½”ë“œ ì™„ì„± ìš”ì²­",
            extra={
                "user_id": user_id,
                "language": request.language,
                "prefix_length": len(request.prefix),
                "suffix_length": len(request.suffix or ""),
                "max_suggestions": request.max_suggestions,
            },
        )
        
        # vLLM ì„œë²„ ìƒíƒœ í™•ì¸
        health_status = await vllm_service.check_health()
        if health_status["status"] != "healthy":
            return CompletionResponse(
                success=False,
                suggestions=[],
                error_message=f"AI ëª¨ë¸ ì„œë²„ ì‚¬ìš© ë¶ˆê°€: {health_status.get('error', 'Unknown error')}",
                processing_time=(datetime.now() - start_time).total_seconds(),
            )
        
        # ì½”ë“œ ì™„ì„± ìš”ì²­ ìƒì„±
        completion_request = CodeGenerationRequest(
            prompt=request.prefix,
            context=request.suffix or "",
            model_type=ModelType.CODE_COMPLETION,
            language=request.language,
            max_tokens=min(200, request.max_suggestions * 50),  # ì œì•ˆë³„ í‰ê·  50í† í°
            temperature=0.1,  # ë‚®ì€ ì°½ì˜ì„±ìœ¼ë¡œ ì •í™•í•œ ì™„ì„±
            top_p=0.9,
        )
        
        # vLLMì„ í†µí•œ ì½”ë“œ ì™„ì„± ìƒì„±
        generation_response = await vllm_service.generate_code_sync(completion_request, user_id)
        
        processing_time = (datetime.now() - start_time).total_seconds()
        
        if not generation_response.success:
            return CompletionResponse(
                success=False,
                suggestions=[],
                error_message=generation_response.error_message,
                processing_time=processing_time,
            )
        
        # ìƒì„±ëœ ì½”ë“œë¥¼ ê°œë³„ ì œì•ˆìœ¼ë¡œ ë¶„í• 
        suggestions = _parse_completion_suggestions(
            generation_response.generated_code,
            request
        )
        
        # ì»¨í…ìŠ¤íŠ¸ ë¶„ì„
        context_analysis = _analyze_completion_context(request)
        
        response = CompletionResponse(
            success=True,
            suggestions=suggestions,
            context_analysis=context_analysis,
            processing_time=processing_time,
            model_used=generation_response.model_used,
            token_usage=generation_response.token_usage,
            completion_length=len(generation_response.generated_code),
            cache_hit=processing_time < 0.1,  # ë¹ ë¥¸ ì‘ë‹µì€ ìºì‹œë¡œ ê°„ì£¼
        )
        
        # ì„±ê³µ ë¡œê¹…
        logger.info(
            f"ì½”ë“œ ì™„ì„± ì„±ê³µ",
            extra={
                "user_id": user_id,
                "suggestions_count": len(suggestions),
                "processing_time": processing_time,
                "cache_hit": response.cache_hit,
            },
        )
        
        # ë°±ê·¸ë¼ìš´ë“œ íƒœìŠ¤í¬ë¡œ í†µê³„ ì—…ë°ì´íŠ¸
        background_tasks.add_task(
            _update_completion_stats,
            user_id,
            len(suggestions),
            processing_time,
            request.language,
        )
        
        return response
        
    except Exception as e:
        processing_time = (datetime.now() - start_time).total_seconds()
        error_msg = f"ì½”ë“œ ì™„ì„± ì‹¤íŒ¨: {str(e)}"
        
        logger.error(
            error_msg,
            extra={
                "user_id": user_id,
                "processing_time": processing_time,
                "exception": str(e),
            },
        )
        
        return CompletionResponse(
            success=False,
            suggestions=[],
            error_message="ì½”ë“œ ì™„ì„± ì¤‘ ì˜ˆìƒì¹˜ ëª»í•œ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤",
            processing_time=processing_time,
        )


# === Enhanced ìƒíƒœ í™•ì¸ ë° í†µê³„ ì—”ë“œí¬ì¸íŠ¸ ===

@router.get("/enhanced/status", summary="Enhanced ëª¨ë“œ ìƒíƒœ í™•ì¸")
async def check_enhanced_status(api_key: str = Depends(get_api_key)):
    """
    Enhanced ëª¨ë“œì˜ ìƒíƒœì™€ ê¸°ëŠ¥ë“¤ì„ í™•ì¸í•©ë‹ˆë‹¤.
    
    **í™•ì¸ í•­ëª©:**
    - ğŸ”§ Enhanced AI ì„œë¹„ìŠ¤ ìƒíƒœ
    - ğŸ—„ï¸ DB ì—°ê²° ë° ì‚¬ìš©ì ì„¤ì • ì„œë¹„ìŠ¤
    - ğŸ¯ ê°œì¸í™” ê¸°ëŠ¥ í™œì„±í™” ìƒíƒœ
    - ğŸ”’ ë³´ì•ˆ ê²€ì¦ ê¸°ëŠ¥ ìƒíƒœ
    """
    try:
        status = {
            "enhanced_available": True,
            "timestamp": datetime.now().isoformat(),
            "components": {},
            "features": {},
        }

        # Enhanced AI ì„œë¹„ìŠ¤ ìƒíƒœ í™•ì¸
        try:
            await enhanced_ai_service.initialize()
            status["components"]["enhanced_ai_service"] = {
                "status": "healthy",
                "message": "Enhanced AI ì„œë¹„ìŠ¤ ì •ìƒ ì‘ë™"
            }
        except Exception as e:
            status["components"]["enhanced_ai_service"] = {
                "status": "error",
                "message": f"Enhanced AI ì„œë¹„ìŠ¤ ì˜¤ë¥˜: {str(e)}"
            }
            status["enhanced_available"] = False

        # DB ì‚¬ìš©ì ì„œë¹„ìŠ¤ ìƒíƒœ í™•ì¸
        try:
            from app.services.user_service import user_service
            # ê°„ë‹¨í•œ ì—°ê²° í…ŒìŠ¤íŠ¸
            test_result = await user_service.get_user_settings("test_token")
            status["components"]["user_service"] = {
                "status": "healthy",
                "message": "ì‚¬ìš©ì ì„¤ì • ì„œë¹„ìŠ¤ ì •ìƒ ì‘ë™"
            }
        except Exception as e:
            status["components"]["user_service"] = {
                "status": "warning",
                "message": f"ì‚¬ìš©ì ì„œë¹„ìŠ¤ ì œí•œì  ì‘ë™: {str(e)}"
            }

        # vLLM ì„œë¹„ìŠ¤ ìƒíƒœ í™•ì¸ (ê¸°ë³¸)
        try:
            vllm_health = await vllm_service.check_health()
            status["components"]["vllm_service"] = {
                "status": "healthy" if vllm_health["status"] == "healthy" else "error",
                "message": vllm_health.get("message", "vLLM ì„œë¹„ìŠ¤ ìƒíƒœ")
            }
        except Exception as e:
            status["components"]["vllm_service"] = {
                "status": "error",
                "message": f"vLLM ì„œë¹„ìŠ¤ ì˜¤ë¥˜: {str(e)}"
            }
            status["enhanced_available"] = False

        # Enhanced ê¸°ëŠ¥ë³„ ìƒíƒœ
        status["features"] = {
            "personalization": status["components"]["user_service"]["status"] in ["healthy", "warning"],
            "security_validation": status["components"]["enhanced_ai_service"]["status"] == "healthy",
            "quality_assessment": True,  # ë¡œì»¬ í•¨ìˆ˜ì´ë¯€ë¡œ í•­ìƒ ì‚¬ìš© ê°€ëŠ¥
            "style_optimization": status["components"]["user_service"]["status"] in ["healthy", "warning"],
        }

        # ì „ì²´ ìƒíƒœ ìš”ì•½
        component_statuses = [comp["status"] for comp in status["components"].values()]
        if all(s == "healthy" for s in component_statuses):
            status["overall"] = "excellent"
        elif any(s == "error" for s in component_statuses):
            status["overall"] = "degraded"
        else:
            status["overall"] = "good"

        structured_logger.log_system_event("Enhanced ìƒíƒœ í™•ì¸", "success", {"overall_status": status['overall']})
        return status

    except Exception as e:
        structured_logger.log_error(e, "Enhanced ìƒíƒœ í™•ì¸")
        return {
            "enhanced_available": False,
            "overall": "error",
            "error": str(e),
            "timestamp": datetime.now().isoformat(),
        }


@router.get("/enhanced/stats", summary="Enhanced ì‚¬ìš© í†µê³„")
async def get_enhanced_stats(api_key: str = Depends(get_api_key)):
    """
    Enhanced ëª¨ë“œ ì‚¬ìš© í†µê³„ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤.
    
    **í†µê³„ í•­ëª©:**
    - ğŸ“Š Enhanced vs Standard ìš”ì²­ ë¹„ìœ¨
    - ğŸ‘¥ ê°œì¸í™” ê¸°ëŠ¥ ì‚¬ìš©ë¥ 
    - ğŸ”’ ë³´ì•ˆ ê²€ì¦ ì‹¤í–‰ íšŸìˆ˜
    - â±ï¸ í‰ê·  ì²˜ë¦¬ ì‹œê°„ ë¹„êµ
    """
    try:
        # ì‹¤ì œ êµ¬í˜„ì—ì„œëŠ” ë°ì´í„°ë² ì´ìŠ¤ë‚˜ ë©”íŠ¸ë¦­ ìŠ¤í† ì–´ì—ì„œ ì¡°íšŒ
        # í˜„ì¬ëŠ” ì˜ˆì‹œ ë°ì´í„° ë°˜í™˜
        stats = {
            "period": "last_24_hours",
            "timestamp": datetime.now().isoformat(),
            "usage": {
                "total_requests": 150,
                "enhanced_requests": 45,
                "standard_requests": 105,
                "enhanced_percentage": 30.0,
            },
            "features": {
                "personalization_used": 38,
                "security_validation_runs": 42,
                "quality_assessments": 45,
                "style_optimizations": 35,
            },
            "performance": {
                "avg_response_time_enhanced": 2.8,
                "avg_response_time_standard": 1.9,
                "overhead_percentage": 47.4,
            },
            "quality": {
                "avg_quality_score": 87.3,
                "quality_distribution": {
                    "excellent": 15,  # 90-100
                    "good": 20,      # 80-89
                    "fair": 8,       # 70-79
                    "poor": 2,       # <70
                }
            },
            "user_satisfaction": {
                "personalization_effectiveness": 92.1,
                "security_confidence": 96.8,
                "code_quality_improvement": 23.4,
            }
        }

        structured_logger.log_system_event("Enhanced í†µê³„ ì¡°íšŒ", "success", {"requests_count": stats["usage"]["total_requests"]})
        return stats

    except Exception as e:
        structured_logger.log_error(e, "Enhanced í†µê³„ ì¡°íšŒ")
        return {
            "error": str(e),
            "timestamp": datetime.now().isoformat(),
        }
